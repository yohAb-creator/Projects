{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d517535-276e-45e7-b28c-34dcd2303cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed4f1c6-90ca-489e-b74e-7d289e9aebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing training set \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa342e3-eba1-47ec-b648-ba17a6623fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing test set \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d0d0b-66a1-4672-b6fe-fcb34e2061d9",
   "metadata": {},
   "source": [
    "# Building CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10fd5ab-94c6-4a12-8149-a18e80dfd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing CNN \n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2c9f9d-236f-4eed-abbe-9f03d3f72446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yohan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Convolution (first fully connected layer)\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation='relu', input_shape = (64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873c661f-b165-47d6-97da-a6531df4f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pooling layer \n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e99e17e-fb3b-4559-b767-c036857f639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second fully connected layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da4981d-3ff2-4ddb-9e45-8c12a1112900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4caf0d7-6b8e-4680-9a15-56d43b642392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full connection and outputlater\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b07d1b-2d5a-40bf-a0ca-1562c3b35873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile \n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a1f3deb-0851-4c65-af55-187e9a7eff0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yohan\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 155ms/step - accuracy: 0.5596 - loss: 0.6822 - val_accuracy: 0.6725 - val_loss: 0.5977\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 146ms/step - accuracy: 0.6910 - loss: 0.5854 - val_accuracy: 0.7295 - val_loss: 0.5380\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 144ms/step - accuracy: 0.7263 - loss: 0.5297 - val_accuracy: 0.7535 - val_loss: 0.5091\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 149ms/step - accuracy: 0.7452 - loss: 0.5157 - val_accuracy: 0.7680 - val_loss: 0.4860\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 147ms/step - accuracy: 0.7609 - loss: 0.4908 - val_accuracy: 0.7740 - val_loss: 0.4737\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 149ms/step - accuracy: 0.7753 - loss: 0.4663 - val_accuracy: 0.7410 - val_loss: 0.5311\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 157ms/step - accuracy: 0.7719 - loss: 0.4756 - val_accuracy: 0.7490 - val_loss: 0.5396\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 147ms/step - accuracy: 0.7913 - loss: 0.4427 - val_accuracy: 0.7930 - val_loss: 0.4743\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 179ms/step - accuracy: 0.7957 - loss: 0.4272 - val_accuracy: 0.7630 - val_loss: 0.5075\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 180ms/step - accuracy: 0.8131 - loss: 0.4031 - val_accuracy: 0.7840 - val_loss: 0.4700\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 151ms/step - accuracy: 0.8189 - loss: 0.3909 - val_accuracy: 0.8005 - val_loss: 0.4553\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 156ms/step - accuracy: 0.8090 - loss: 0.3973 - val_accuracy: 0.8025 - val_loss: 0.4547\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 157ms/step - accuracy: 0.8262 - loss: 0.3762 - val_accuracy: 0.7930 - val_loss: 0.4494\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 148ms/step - accuracy: 0.8258 - loss: 0.3792 - val_accuracy: 0.8015 - val_loss: 0.4581\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 207ms/step - accuracy: 0.8371 - loss: 0.3614 - val_accuracy: 0.8020 - val_loss: 0.4918\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 411ms/step - accuracy: 0.8394 - loss: 0.3503 - val_accuracy: 0.8035 - val_loss: 0.4503\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.8506 - loss: 0.3358 - val_accuracy: 0.8090 - val_loss: 0.4462\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 153ms/step - accuracy: 0.8639 - loss: 0.3181 - val_accuracy: 0.8000 - val_loss: 0.4756\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.8528 - loss: 0.3312 - val_accuracy: 0.8065 - val_loss: 0.4474\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 159ms/step - accuracy: 0.8704 - loss: 0.2938 - val_accuracy: 0.8025 - val_loss: 0.4551\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 154ms/step - accuracy: 0.8763 - loss: 0.2899 - val_accuracy: 0.7985 - val_loss: 0.4961\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.8719 - loss: 0.2845 - val_accuracy: 0.7890 - val_loss: 0.5464\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 175ms/step - accuracy: 0.8856 - loss: 0.2647 - val_accuracy: 0.7890 - val_loss: 0.5215\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 162ms/step - accuracy: 0.8926 - loss: 0.2503 - val_accuracy: 0.7970 - val_loss: 0.5304\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 153ms/step - accuracy: 0.8907 - loss: 0.2588 - val_accuracy: 0.8065 - val_loss: 0.4894\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 153ms/step - accuracy: 0.9001 - loss: 0.2417 - val_accuracy: 0.7680 - val_loss: 0.6620\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.9071 - loss: 0.2266 - val_accuracy: 0.7740 - val_loss: 0.6683\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 154ms/step - accuracy: 0.9044 - loss: 0.2287 - val_accuracy: 0.8070 - val_loss: 0.5708\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 153ms/step - accuracy: 0.9128 - loss: 0.2099 - val_accuracy: 0.8030 - val_loss: 0.5449\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 165ms/step - accuracy: 0.9187 - loss: 0.2004 - val_accuracy: 0.8005 - val_loss: 0.5566\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.9150 - loss: 0.2068 - val_accuracy: 0.8040 - val_loss: 0.5475\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.9270 - loss: 0.1783 - val_accuracy: 0.7770 - val_loss: 0.6900\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.9266 - loss: 0.1857 - val_accuracy: 0.7910 - val_loss: 0.5852\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 161ms/step - accuracy: 0.9322 - loss: 0.1681 - val_accuracy: 0.8110 - val_loss: 0.5818\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 157ms/step - accuracy: 0.9424 - loss: 0.1566 - val_accuracy: 0.8115 - val_loss: 0.5632\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.9360 - loss: 0.1613 - val_accuracy: 0.7895 - val_loss: 0.5954\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 156ms/step - accuracy: 0.9423 - loss: 0.1536 - val_accuracy: 0.7920 - val_loss: 0.6942\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.9415 - loss: 0.1488 - val_accuracy: 0.7950 - val_loss: 0.7298\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 155ms/step - accuracy: 0.9425 - loss: 0.1519 - val_accuracy: 0.8020 - val_loss: 0.6533\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 158ms/step - accuracy: 0.9509 - loss: 0.1277 - val_accuracy: 0.7865 - val_loss: 0.7529\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.9490 - loss: 0.1259 - val_accuracy: 0.8010 - val_loss: 0.7110\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 171ms/step - accuracy: 0.9518 - loss: 0.1300 - val_accuracy: 0.7825 - val_loss: 0.7617\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 159ms/step - accuracy: 0.9521 - loss: 0.1226 - val_accuracy: 0.7955 - val_loss: 0.7405\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 159ms/step - accuracy: 0.9487 - loss: 0.1277 - val_accuracy: 0.7975 - val_loss: 0.7109\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 173ms/step - accuracy: 0.9566 - loss: 0.1162 - val_accuracy: 0.8070 - val_loss: 0.7259\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 168ms/step - accuracy: 0.9648 - loss: 0.1008 - val_accuracy: 0.8075 - val_loss: 0.7815\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.9582 - loss: 0.1123 - val_accuracy: 0.7800 - val_loss: 0.9071\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 163ms/step - accuracy: 0.9504 - loss: 0.1241 - val_accuracy: 0.7985 - val_loss: 0.8058\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.9630 - loss: 0.1017 - val_accuracy: 0.8150 - val_loss: 0.7172\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 161ms/step - accuracy: 0.9698 - loss: 0.0879 - val_accuracy: 0.8045 - val_loss: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a135795a60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the CNN \n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe5ff72-c063-438e-94bd-6879b7ba95b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "# make a single prediction\n",
    "cnn.save(\"C:/Users/yohan/dataset/cnn.keras\")\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "image_path = \"C:/Users/yohan/dataset/single_prediction/Lily_pet.jpg\"\n",
    "test_image = image.load_img(image_path, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "results = cnn.predict(test_image)\n",
    "if results[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6ecefc5-e675-494c-b010-bfbe9a6a8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "# Initialize the main screen\n",
    "screen = Tk()\n",
    "screen.title(\"Identify Animal\")\n",
    "screen.geometry(\"600x400\")  # Fixed size to match the background\n",
    "\n",
    "# Load and resize the image\n",
    "\n",
    "\n",
    "try:\n",
    "    # Open and resize image\n",
    "    bg_image = Image.open(image_path)\n",
    "    bg_image = bg_image.resize((600, 400), Image.LANCZOS)  # Resize to fit window\n",
    "    bg = ImageTk.PhotoImage(bg_image)  # Convert for Tkinter use\n",
    "\n",
    "    # Keep a reference to prevent garbage collection\n",
    "    screen.bg = bg  \n",
    "\n",
    "    # Set background image\n",
    "    bg_label = Label(screen, image=screen.bg)\n",
    "    bg_label.place(relwidth=1, relheight=1)  # Make it fill the window\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error loading image:\", e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Button function\n",
    "def button_pressed():\n",
    "    canvas = Canvas(screen, width=600, height=400, highlightthickness=0)\n",
    "    canvas.place(relwidth=1, relheight=1)\n",
    "\n",
    "    # Add the background image\n",
    "    canvas.create_image(0, 0, image=screen.bg, anchor=\"nw\")\n",
    "\n",
    "    # Add transparent text\n",
    "    text_id = canvas.create_text(300, 50, text=f\"{prediction}!\", font=('Arial', 20, 'bold'), fill=\"white\")\n",
    "\n",
    "\n",
    "# Create a button\n",
    "button = Button(screen, text=\"Identify\", command=button_pressed)\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Run the GUI event loop\n",
    "screen.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca998f58-9690-4386-b41d-1506976e6512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
